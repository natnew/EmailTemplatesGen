{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install transformers datasets nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained T5 model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of email dataset\n",
    "# Replace with your own email dataset (this is just a placeholder)\n",
    "emails = [\n",
    "    {\"email_body\": \"Thank you for attending the meeting. Please find attached the proposal.\"},\n",
    "    {\"email_body\": \"It was a pleasure meeting you. Attached are the necessary documents for the next steps.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"email_body\"], padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "email_dataset = Dataset.from_dict({\"email_body\": [email[\"email_body\"] for email in emails]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "tokenized_emails = email_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for T5 training by formatting it properly\n",
    "def process_data_to_model_inputs(batch):\n",
    "    inputs = batch[\"email_body\"]\n",
    "    batch[\"input_ids\"] = tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=512)[\"input_ids\"]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "tokenized_emails = tokenized_emails.map(process_data_to_model_inputs, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set format for PyTorch\n",
    "tokenized_emails.set_format(type=\"torch\", columns=[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fine_tuned_t5\",          # Output directory to save the model\n",
    "    per_device_train_batch_size=4,         # Batch size per device during training\n",
    "    num_train_epochs=3,                    # Number of training epochs\n",
    "    save_steps=500,                        # How often to save the model\n",
    "    save_total_limit=2,                    # Limit the number of saved checkpoints\n",
    "    logging_dir=\"./logs\",                  # Directory to save logs\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"epoch\",           # Evaluate after every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                           # The T5 model instance\n",
    "    args=training_args,                    # Training arguments we defined above\n",
    "    train_dataset=tokenized_emails,        # The tokenized email dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./fine_tuned_t5\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_t5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of generating a new email template using the fine-tuned T5 model\n",
    "def generate_email_t5(prompt):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    generated_ids = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new email template with the fine-tuned T5 model\n",
    "prompt = \"Generate a follow-up email after a meeting regarding a project proposal.\"\n",
    "generated_email = generate_email_t5(prompt)\n",
    "\n",
    "print(\"T5 Generated Email:\\n\", generated_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
