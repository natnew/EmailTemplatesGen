from google.colab import drive
drive.mount('/content/drive')

# Import necessary libraries
import pandas as pd
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import os

# Download necessary NLTK resources
import nltk
nltk.download('punkt_tab')
nltk.download('punkt')
nltk.download('stopwords')

# Load raw email data
def load_emails():
    # Load raw email data from text files
    # files = ['/content/drive/My Drive/data/raw/Conference_Meetup.txt', 
            # '/content/drive/My Drive/data/raw/Delivering_Annual_Impact_Factor_Report.txt', 
            # '/content/drive/My Drive/data/raw/Delivering_Annual_Publishers_Report.txt', 
            # '/content/drive/My Drive/data/raw/Delivering_Contractual_Notice.txt',
            # '/content/drive/My Drive/data/raw/Delivering_Royalty_Statements.txt',
            # '/content/drive/My Drive/data/raw/Editor_Search_Invitation.txt',
            # '/content/drive/My Drive/data/raw/Editorial_Board_Recruitment.txt',
            # '/content/drive/My Drive/data/raw/Impact_Factor_Initial_Announcement.txt',
            # '/content/drive/My Drive/data/raw/Industry_Initiative_Annoucement.txt',
            # '/content/drive/My Drive/data/raw/New_Editorship_Offer.txt']
    raw_data_list = []
    for file in files:
        with open(file, 'r') as f:
            text = f.read()
            raw_data_list.append({'text': text})
    
    raw_data = pd.DataFrame(raw_data_list)
    return raw_data

# Example: Clean and tokenize text
stop_words = set(stopwords.words('english'))

def preprocess(text):
    tokens = word_tokenize(text.lower())  # Convert to lowercase and tokenize
    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]  # Remove non-alphanumeric tokens and stopwords
    return tokens

def clean_email_data(raw_data):
    # Apply the preprocessing function to the 'text' column and store results in 'clean_text'
    raw_data['clean_text'] = raw_data['text'].apply(preprocess)
    return raw_data

# Check current working directory
print(f"Current working directory: {os.getcwd()}")

# Load and clean the email data
raw_data = load_emails()
if raw_data.empty:
    print("No data loaded. Please check the file paths.")
else:
    clean_data = clean_email_data(raw_data)
    print(clean_data)
