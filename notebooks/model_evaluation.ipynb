{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install transformers datasets nltk rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import nltk\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, BartForConditionalGeneration, BartTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned GPT-2 model\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"./fine_tuned_gpt2\")\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"./fine_tuned_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned BART model\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(\"./fine_tuned_bart\")\n",
    "bart_tokenizer = BartTokenizer.from_pretrained(\"./fine_tuned_bart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation function for BLEU score\n",
    "def evaluate_bleu(reference, generated):\n",
    "    reference = [nltk.word_tokenize(reference)]\n",
    "    generated = nltk.word_tokenize(generated)\n",
    "    smoothing_function = SmoothingFunction().method4\n",
    "    return sentence_bleu(reference, generated, smoothing_function=smoothing_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation function for ROUGE score\n",
    "def evaluate_rouge(reference, generated):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    return scorer.score(reference, generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test input for both models\n",
    "context = \"Please find the attached report regarding our recent meeting.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate with GPT-2\n",
    "gpt2_inputs = gpt2_tokenizer(context, return_tensors=\"pt\")\n",
    "gpt2_output = gpt2_model.generate(gpt2_inputs['input_ids'], max_length=100, temperature=0.7, top_p=0.9)\n",
    "gpt2_generated = gpt2_tokenizer.decode(gpt2_output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate with BART\n",
    "bart_inputs = bart_tokenizer(context, return_tensors=\"pt\")\n",
    "bart_output = bart_model.generate(bart_inputs['input_ids'], max_length=100, temperature=0.7, top_p=0.9)\n",
    "bart_generated = bart_tokenizer.decode(bart_output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference text for evaluation\n",
    "reference_text = \"Please find the attached report we discussed in our meeting.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate BLEU scores\n",
    "gpt2_bleu = evaluate_bleu(reference_text, gpt2_generated)\n",
    "bart_bleu = evaluate_bleu(reference_text, bart_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ROUGE scores\n",
    "gpt2_rouge = evaluate_rouge(reference_text, gpt2_generated)\n",
    "bart_rouge = evaluate_rouge(reference_text, bart_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(f\"GPT-2 Generated Text: {gpt2_generated}\")\n",
    "print(f\"BART Generated Text: {bart_generated}\")\n",
    "print(f\"GPT-2 BLEU Score: {gpt2_bleu}\")\n",
    "print(f\"BART BLEU Score: {bart_bleu}\")\n",
    "print(f\"GPT-2 ROUGE Score: {gpt2_rouge}\")\n",
    "print(f\"BART ROUGE Score: {bart_rouge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
